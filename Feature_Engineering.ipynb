{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering\n",
        "#Theory Questions\n",
        "\n",
        "1. What is a parameter?\n",
        "-> A parameter in machine learning refers to a configuration variable that is internal to the model and is learned from the training data. For example, in linear regression, the slope and intercept of the line are parameters that the model adjusts to minimize the error between predicted and actual values.\n",
        "\n",
        "2. What is correlation?\n",
        "-> Correlation measures the strength and direction of a linear relationship between two variables. It is quantified by the correlation coefficient, which ranges from -1 to 1. A coefficient close to 1 indicates a strong positive correlation, while a coefficient close to -1 indicates a strong negative correlation.\n",
        "\n",
        "3. What does negative correlation mean?\n",
        "-> Negative correlation indicates that as one variable increases, the other variable tends to decrease. For example, in a study of exercise and weight, a negative correlation would suggest that higher levels of exercise are associated with lower body weight, reflecting an inverse relationship between the two variables.\n",
        "\n",
        "4. Define Machine Learning.\n",
        "-> Machine Learning is a subset of artificial intelligence that enables systems to learn from data, identify patterns, and make decisions with minimal human intervention. It involves algorithms that improve their performance on a task as they are exposed to more data, such as predicting house prices based on features like size and location.\n",
        "\n",
        "5. What are the main components in Machine Learning?\n",
        "-> The main components of machine learning include data, algorithms, models, and evaluation metrics. Data is the foundation, algorithms are the methods used to learn from data, models are the representations of learned patterns, and evaluation metrics assess model performance, such as accuracy or F1 score.\n",
        "\n",
        "6. How does loss value help in determining whether the model is good or not?\n",
        "-> The loss value quantifies how well a model's predictions match the actual outcomes. A lower loss indicates better model performance, while a higher loss suggests poor predictions. For instance, in regression, mean squared error (MSE) is commonly used; a decreasing MSE during training indicates improvement in the model's accuracy.\n",
        "\n",
        "7. What are continuous and categorical variables?\n",
        "-> Continuous variables are numerical values that can take any value within a range, such as height or temperature. Categorical variables represent distinct categories or groups, such as gender or color. They can be nominal (no order) or ordinal (with order), influencing how data is analyzed and modeled.\n",
        "\n",
        "8. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "-> Categorical variables can be handled using techniques like one-hot encoding, which creates binary columns for each category, or label encoding, which assigns a unique integer to each category. For example, converting \"red,\" \"blue,\" and \"green\" into binary columns allows algorithms to process categorical data effectively.\n",
        "\n",
        "9. What do you mean by training and testing a dataset?\n",
        "-> Training and testing datasets are subsets of data used in machine learning. The training dataset is used to train the model, allowing it to learn patterns, while the testing dataset evaluates the model's performance on unseen data, ensuring it generalizes well to new inputs and does not overfit.\n",
        "\n",
        "10. What is sklearn.preprocessing?\n",
        "-> sklearn.preprocessing is a module in the Scikit-learn library that provides functions to preprocess data before training machine learning models. It includes tools for scaling features, encoding categorical variables, and normalizing data, which help improve model performance and ensure that different features contribute equally to the learning process.\n",
        "\n",
        "11. What is a Test set?\n",
        "-> A test set is a portion of the dataset that is reserved for evaluating the performance of a trained machine learning model. It is not used during the training phase, allowing for an unbiased assessment of how well the model generalizes to new, unseen data, ensuring its effectiveness in real-world applications.\n",
        "\n",
        "12. How do we split data for model fitting (training and testing) in Python?\n",
        "-> In Python, data can be split into training and testing sets using the train_test_split function from the Scikit-learn library. For example, train_test_split(X, y, test_size=0.2) splits the dataset into 80% training and 20% testing, ensuring a random distribution of data points for robust model evaluation.\n",
        "\n",
        "13. How do you approach a Machine Learning problem?\n",
        "-> To approach a machine learning problem, first, define the objective and gather relevant data. Next, perform exploratory data analysis (EDA) to understand data characteristics, preprocess the data (cleaning, encoding, scaling), select appropriate algorithms, train the model, evaluate its performance, and iterate to improve results.\n",
        "\n",
        "14. Why do we have to perform EDA before fitting a model to the data?\n",
        "-> Exploratory Data Analysis (EDA) is crucial before model fitting as it helps identify data patterns, distributions, and potential issues like missing values or outliers. EDA informs feature selection, guides preprocessing steps, and enhances understanding of relationships between variables, ultimately leading to better model performance and accuracy.\n",
        "\n",
        "15. What is causation?\n",
        "-> Causation refers to a relationship where one event directly influences another. For example, smoking causes an increased risk of lung cancer. Establishing causation requires more rigorous analysis than correlation, often involving controlled experiments or longitudinal studies to demonstrate that changes in one variable lead to changes in another.\n",
        "\n",
        "16. Explain the difference between correlation and causation with an example.\n",
        "-> Correlation indicates a relationship between two variables, while causation implies that one variable directly affects the other. For example, ice cream sales and drowning incidents may correlate due to both increasing in summer, but ice cream sales do not cause drowning; they are influenced by the warmer weather.\n",
        "\n",
        "17. What is an Optimizer?\n",
        "-> An optimizer is an algorithm used to adjust the parameters of a machine learning model to minimize the loss function during training. Optimizers help improve model performance by finding the best parameter values that reduce prediction errors, ensuring the model learns effectively from the training data.\n",
        "\n",
        "18. What are different types of optimizers? Explain each with an example.\n",
        "-> Common types of optimizers include:\n",
        "* Gradient Descent: Updates parameters based on the gradient of the loss function. Example: Stochastic Gradient Descent (SGD) updates parameters using a single data point at a time.\n",
        "* Adam: Combines momentum and adaptive learning rates, adjusting learning rates for each parameter. Example: Used in deep learning for faster convergence.\n",
        "* RMSprop: Adapts learning rates based on recent gradients, preventing oscillations. Example: Effective in training recurrent neural networks.\n",
        "\n",
        "19. What is sklearn.linear_model?\n",
        "-> sklearn.linear_model is a module in Scikit-learn that provides linear models for regression and classification tasks. It includes algorithms like Linear Regression, Logistic Regression, and Ridge Regression, allowing users to fit linear models to data, making predictions based on linear relationships between features and target variables.\n",
        "\n",
        "20. What does model.fit() do? What arguments must be given?\n",
        "-> The model.fit() method trains a machine learning model on the provided training data. It requires at least two arguments: the feature set (X) and the target variable (y). For example, model.fit(X_train, y_train) adjusts the model parameters to minimize the loss function based on the training data.\n",
        "\n",
        "21. What does model.predict() do? What arguments must be given?\n",
        "-> The model.predict() method generates predictions for new data based on the trained model. It requires the feature set (X) as an argument. For example, predictions = model.predict(X_test) uses the test data to produce output values, allowing evaluation of the model's performance on unseen data.\n",
        "\n",
        "22. What is feature scaling? How does it help in Machine Learning?\n",
        "-> Feature scaling standardizes the range of independent variables or features in a dataset. It helps improve model performance by ensuring that all features contribute equally to the distance calculations in algorithms like k-NN or gradient descent, preventing features with larger ranges from dominating the learning process.\n",
        "\n",
        "23. How do we perform scaling in Python?\n",
        "-> In Python, scaling can be performed using the StandardScaler or MinMaxScaler from the Scikit-learn library. For example, to standardize features, you can use:\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "This scales the features to have a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "24. What is sklearn.preprocessing?\n",
        "-> sklearn.preprocessing is a module in Scikit-learn that provides tools for transforming and preparing data for machine learning. It includes functions for scaling features, encoding categorical variables, normalizing data, and creating polynomial features, ensuring that the data is in a suitable format for model training.\n",
        "\n",
        "25. Explain data encoding.\n",
        "-> Data encoding is the process of converting categorical variables into a numerical format that machine learning algorithms can understand. Techniques include one-hot encoding, which creates binary columns for each category, and label encoding, which assigns unique integers to categories. This transformation is essential for effective model training and performance."
      ],
      "metadata": {
        "id": "m83tgpZfeTye"
      }
    }
  ]
}